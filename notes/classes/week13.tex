\section{Monday 11/18/2024}
Project 2 has been released and the problems are available to select.
\subsection{Machine Learning Interpretations}
\subsubsection{Taylor Expansion}
\begin{equation}
  h(x) - h(x_0) \approx h^\prime(x_0)(x-x_0) + \frac{1}{2} h^{\prime \prime}(x_0)(x-x_0)^2 + \dots
\end{equation}
\subsubsection{Activation Functions and Neural Networks}
We can approximate functions with taylor expansions. However, activation functions such as
\begin{equation}
  \Phi(x) = Z \max \{ yx,0  \} 
\end{equation}
can represent a wide variety of non-linear functions. These can be combined together with random initialization of each $y$ and $Z$.