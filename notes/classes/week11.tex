\section{Monday 11/04/2024}
\subsection{Optimization Algorithms for Unconstrained Problems 3}
\subsubsection{Meta-Heuristics}
There are heuristic optimization algorithms that try to exploit some intuitive understanding of the original problem and use that to find the best solution instead of some problem-agnostic algorithm like gradient descent. Genetic algorithms are algorithms that create different generations of solutions with characteristics and a "fitness" score. At each iteration, the probability of an algorithm surviving is defined by its fitness score and then a new generation is created from the solutions that survived. At each generation, there is a mutation process that can introduce new characteristics into the solutions.
\subsection{Optimization Algorithms for Constrained Problems}
A constrained optimization problem can be transformed into an unconstrained problem by introducing a cost to each constraint in the objective function.
\begin{equation}
  \begin{aligned}
    \text{minimize } f(x) \\
    \text{subject to } g(x) \leq 0 \\
    h(x) = 0
  \end{aligned}
\end{equation}
Can be turned into
\begin{equation}
  \text{minimize } f(x) + \lambda g(x) + \nu h(x)
\end{equation}

\subsubsection{Projection-based method}
Mirror descent is an optimization method that allows us to alter the unconstrained case of gradient descent and change it into the constrained case. We introduce the domain and restrict it to a convex set $\Omega \subseteq \mathbb{R}^d$

\section{Wednesday 11/06/2024}
\subsection{Projection-based Methods}
Projection-based methods work well with gradient methods, also known as first-order methods. 
\subsubsection{Mirror Descent}
For some convex set $\Omega \subseteq \mathbb{R}^d$, we can change the unconstrained gradient descent from 
\begin{equation}
  \min_{x \in \mathbb{R}^d } f(\textbf{x}^{k-1}) + \langle \nabla f(\textbf{x}^{k-1}), \textbf{x} - \textbf{x}^{k-1}  \rangle + \frac{1}{2 \alpha^{k-1}} \| \textbf{x} - \textbf{x}^{k-1} \|_2^2
\end{equation}
to 
\begin{equation}
  \min_{x \in \Omega } f(\textbf{x}^{k-1}) + \langle \nabla f(\textbf{x}^{k-1}), \textbf{x} - \textbf{x}^{k-1}  \rangle + \frac{1}{2 \alpha^{k-1}} \| \textbf{x} - \textbf{x}^{k-1} \|_2^2
\end{equation}
This works because we are taking the feasible region that would otherwise be defined by the constraints $g(x),h(x)$ and we bring the intersection of all constraints into the minimization problem. Frequently, these convex sets fall into the general sets below:
\begin{itemize}
  \item $\Omega = \{ x | x \geq 0 \}$
  \item $\Omega = \{ x | a \leq x \leq b \}$
  \item $\Omega = \{ x | \| x \| \leq R \}$
\end{itemize}

The previous equation is also equivalent to euclidean projection.
\begin{equation}
  \min_{x \in \Omega} \frac{1}{2} \| \textbf{x}^{k-1} - \alpha^{k-1} \nabla f(\textbf{x}^{k-1}) - \textbf{x}\|_2^2
\end{equation}
Here, we can bring back the definition that $\textbf{x}^k = \textbf{x}^{k-1} - \alpha^{k-1} \nabla f(\textbf{x}^{k-1})$. This means that the above equation can be interpreted as us finding the $\textbf{x}$ that is closest to our previous (potentially infeasible) guess of $\textbf{x}^k$. In other words, we are letting gradient descent pick infeasible or feasible solutions, and then we are finding the projection of the infeasible solutions onto the feasible region.
\subsubsection{Non-negative set}
If we define $\Omega = \{ x | x \geq 0 \}$ we can write the gradient descent as 
\begin{equation}
  \min_{x \geq 0 } \| \textbf{y}^k - \textbf{x}\|_2^2
\end{equation}
where the optimal solution is
\begin{equation}
  x_i = 
  \begin{cases}
    y_i^k & y_i^k \geq 0 \\
    0 & o.w.
  \end{cases}
\end{equation}
In this special case where the domain is restricted to $\Omega = \{ x | x \geq 0 \}$, this also applies for any norm in this specific set.

\subsubsection{Upper/Lower bounds}
Now we define the convex set that restricts the gradient descent domain as $\Omega = \{ x | a \leq x \leq b \}$
\begin{equation}
  \min_{a \leq x \leq b } \| \textbf{y}^k - \textbf{x}\|_2^2
\end{equation}
where the optimal solution is
\begin{equation}
  x_i = 
  \begin{cases}
    y_i^k & y_i^k \in [a_i,b_i] \\
    b_i & y_i^k > b_i \\
    a_i & y_i^K < a_i
  \end{cases}
\end{equation}
This is also a rather trivial solution. 
\subsubsection{Euclidean ball}
Now we define the convex set as $\Omega = \{ x | \| x \|_2 \leq R \}$. This is a euclidean ball with radius $R$.

\begin{equation}
  \min_{\| x \|_2 \leq R} \| \textbf{y}^k - \textbf{x}\|_2^2
\end{equation}

In this case, if the fixed point $y^k$ is outside of the feasible region, the point on the edge of the feasible region will have a tangent with a normal that runs through the point $y^k$.
\begin{figure}[htbp]
  \centerline{\includegraphics[width=0.75\textwidth]{images/euclidean_ball.png}}
  \caption{Euclidean ball with the infeasible point $y^k$}
  \label{fig:euclidean_ball}
\end{figure}

The optimal solution here is the point on the line that lies on the boundary of the surface of the euclidean ball.
We can also extend the $l_2$-norm to be any $l_p$-norm.

\section{Friday 11/08/2024}
\subsection{Stochastic Programming: Solutions Methods}
Can we still perform optimization in the event that we don't know all of the problem parameters with absolute certainty.
\subsubsection{Newsvendor Problem}
This is an inventory problem with the following setup:
\begin{itemize}
  \item $\xi$: Uncertain daily demand for a daily newspaper
  \item $x$: Decision about the quantity of newspapers to be purchased from distributor
  \item $c$: Cost to be paid by the newsvendor for one paper at the beginning of the day
  \item $s$: Selling price for one newspaper
  \item $r$: Return price for one unsold newspaper at the end of the day.
\end{itemize} 
What is the profit? (Assuming that $0\leq r < c < s$)
We want to maximize the quantity of profit defined below
\begin{equation}
  \Pi(x,\xi) = 
  \begin{cases}
    s\xi - cx + r(x-\xi) & x \geq \xi \\
    sx -cx & o.w.
  \end{cases}
\end{equation}

This can be aggregated into one function 
\begin{equation}
  \Pi(x,\xi) = (s-c)x - (s-r) \max \{ 0, x-\xi \}
\end{equation}

Since $\xi$ is a random variable. We can find the expected profit as
\begin{equation}
  \mathbb{E}[f(x,\xi)] = \sum_{k=0}^\infty \mathbb{P}_\xi (k) f(x,k)
\end{equation}
where $\mathbb{P}_\xi$ is the PMF of $\xi$. Then, the complete optimization problem we want to maximize for the newsvendor problem is

\begin{align}
  \text{maximize} & \quad \mathbb{E}[f(x,\xi)] \\
  \text{subject to} & \quad x \geq 0
\end{align}

\subsubsection{General Case}

This concept of stochastic programming extends to the general optimization case where all objectives and constraints can depend on a random variable.

\begin{align}
  \text{minimize} & \quad \mathbb{E}[f(x,\xi_1)] \\
  \text{subject to} & \quad \mathbb{E}[g(x,\xi_2)] \leq 0\\
  & \quad \mathbb{E}[h(x,\xi_3)] = 0
\end{align}

Since variance is also an expectation, defined as $Var(x) = \mathbb{E}[(x-\mathbb{E}[x])^2]$, we can minimize different moments of the function. (Variance is the second moment of a random variable).

\subsubsection{Portfolio Optimization}
\begin{itemize}
  \item 1 unit of money invested on $n$-many stocks.
  \item $\textbf{x}$ portfolio of investment (how much percentage to be allocated to which stock).
  \item Unit return $r \in \mathbb{R}^n$ is a random vector.
\end{itemize}

Expected return for one portfolio is defined as
\begin{equation}
  \mathbb{E}[r^T \textbf{x}]
\end{equation}
It is natural to want to maximize this expected return. However, in financial engineering this is not done because a high average may still be quite risky. For example, a function that has a $51\%$ chance of returning $\$1,000,000$ and a 49\% chance of losing \$1,000,000. The average return will be high but this is a very risky choice. So instead, the variance of the return (the risk of the portfolio) is minimized.
\begin{equation}
  Var(\textbf{x}) = \mathbb{E}[\textbf{x}^T(r-\mathbb{E}[r])(r^T -\mathbb{E}[r^T])\textbf{x}]
\end{equation}

So, the "population-level" Markowitz model for portfolio optimization is a combination of return and variance
\begin{align}
  \text{minimize} & \quad -\mathbb{E}[r^T \textbf{x}] + \gamma \mathbb{E}[\textbf{x}^T(r-\mathbb{E}[r])(r^T -\mathbb{E}[r^T])\textbf{x}] \\
  \text{subject to} & \quad \textbf{1}^T \textbf{x} = 1 \\
  & \quad \textbf{x} \geq \textbf{0}
\end{align}

\subsubsection{Stochastic Programming and Machine Learning}
We are given data generated from a linear model
\begin{equation}
  y = \alpha^\top \textbf{x}^{true} + w
\end{equation}
where $\alpha \in \mathbb{R}^n, w \in \mathbb{R}$ are random.

Given observations about $\alpha, \beta$, how do we find $\textbf{x}^{true}$

Given fitting parameters $\textbf{x}$, what is the mean prediction error?
\begin{equation}
  \mathbb{E}[(\alpha^\top \textbf{x} - \beta)^2]
\end{equation}
How to find the best $\textbf{x}$ such that the prediction error is minimized on average? \\

"Population-level" linear regression problem.
\begin{align}
  \text{minimize} & \quad \mathbb{E}[(\alpha^\top \textbf{x} - \beta)^2]
\end{align}